{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pratikgiri_Goswami_c0806977.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikgirigoswami/Bird-Classification-Using-ResNet/blob/main/Pratikgiri_Goswami_c0806977.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZwiRG4aHFox"
      },
      "source": [
        "MidTerm Assignment\n",
        "\n",
        "Student Name: Pratikgiri Goswami\n",
        "\n",
        "Student ID: C0806977\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOFn-HItG3GT"
      },
      "source": [
        "Step-1: Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g10dhBVw-pIz"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import random\n",
        "import shutil\n",
        "plt.ion()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbXNKsaGv22"
      },
      "source": [
        "Step-2: Importing CUB Bird dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T33dOAaY1rEn"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'pratikzg'\n",
        "os.environ['KAGGLE_KEY'] = '15eded5f641208c4012e9015dfd52e49'\n",
        "\n",
        "!pip install kaggle\n",
        "!kaggle datasets download veeralakrishna/200-bird-species-with-11788-images --unzip\n",
        "\n",
        "ROOT = 'data'\n",
        "datasets.utils.extract_archive('CUB_200_2011.tgz', ROOT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUoyq7-UHryj"
      },
      "source": [
        "Step-3: Dividing entire dataset into two parts, Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zza1YR-B2BXP"
      },
      "source": [
        "TRAIN_RATIO = 0.9\n",
        "\n",
        "data_dir = os.path.join(ROOT, 'CUB_200_2011')\n",
        "images_dir = os.path.join(data_dir, 'images')\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "if os.path.exists(train_dir):\n",
        "    shutil.rmtree(train_dir) \n",
        "if os.path.exists(val_dir):\n",
        "    shutil.rmtree(val_dir)\n",
        "    \n",
        "os.makedirs(train_dir)\n",
        "os.makedirs(val_dir)\n",
        "\n",
        "classes = os.listdir(images_dir)\n",
        "for c in classes:\n",
        "    \n",
        "    class_dir = os.path.join(images_dir, c)\n",
        "    images = os.listdir(class_dir)\n",
        "    n_train = int(len(images) * TRAIN_RATIO)\n",
        "    train_images = images[:n_train]\n",
        "    val_images = images[n_train:]\n",
        "    \n",
        "    os.makedirs(os.path.join(train_dir, c), exist_ok = True)\n",
        "    os.makedirs(os.path.join(val_dir, c), exist_ok = True)\n",
        "    \n",
        "    for image in train_images:\n",
        "        image_src = os.path.join(class_dir, image)\n",
        "        image_dst = os.path.join(train_dir, c, image) \n",
        "        shutil.copyfile(image_src, image_dst)\n",
        "        \n",
        "    for image in val_images:\n",
        "        image_src = os.path.join(class_dir, image)\n",
        "        image_dst = os.path.join(val_dir, c, image) \n",
        "        shutil.copyfile(image_src, image_dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31vr74ehID6n"
      },
      "source": [
        "Step-4: Preprocessing images for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAHCpwE0-wa8"
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "'''\n",
        "Dataset is also uploaded on Google Drive\n",
        "In that case, following lines should be executed\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive/', force_remount = True)\n",
        "'''\n",
        "# Accessing data from local directory\n",
        "data_dir = '/content/data/CUB_200_2011'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u9hyJIRIb8x"
      },
      "source": [
        "Step-5: Extracting class names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j52JlLzu_dm2"
      },
      "source": [
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqGj88BgKT9N"
      },
      "source": [
        "Step-6: Default class names have numbers in beginning which may overlap while showing images. Hence, it is better to remove numbers and keep names of birds only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07Qh5d__J3mn"
      },
      "source": [
        "# To format class names without numbering\n",
        "def format_label(label):\n",
        "    label = label.split('.')[-1]\n",
        "    label = label.replace('_', ' ')\n",
        "    label = label.title()\n",
        "    label = label.replace(' ', '')\n",
        "    return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cQyNaD2yRQx"
      },
      "source": [
        "# Updated class names\n",
        "class_names = [format_label(c) for c in class_names]\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZt-AuU0KidA"
      },
      "source": [
        "Step-7: Visualizing a few images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf1_N2UfBhJf"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S270dE_UPOGA"
      },
      "source": [
        "Step-8: Function for training the model with scheduling Learning Rate and saving the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJNUJZnTB7Ya"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-hOw32oQjbv"
      },
      "source": [
        "Step-9: Function for visualizing a few predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWjOfU2DCOQS"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('Predicted: {} \\n Truth: {}'.format(class_names[preds[j]], class_names[labels[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqd23ic-RPG9"
      },
      "source": [
        "Step-10: Loading a pre-trained model and tuning the final layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l0XqF6FCr18"
      },
      "source": [
        "# I HAVE RUN ALL THREE RESNET VERSIONS AND MADE COMPARISONS\n",
        "# COMPARISON OF DIFFERENT MODELS IS DESCRIBED IN REPORT SUBMITTED\n",
        "\n",
        "#model_ft = models.resnet34(pretrained=True)\n",
        "#model_ft = models.resnet50(pretrained=True)\n",
        "model_ft = models.resnet152(pretrained=True)\n",
        "\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG6epcwvmy10"
      },
      "source": [
        "# Pre-trained & modified Resnet model\n",
        "# We can see that the model has now 200 outputs\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92xjC_mdSmpF"
      },
      "source": [
        "Step-11: Training model and evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lbBoeSiDIyd"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bDMqux9S3GL"
      },
      "source": [
        "Step-12: Visualizing predicted images. Predicted and True classnames both are shown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gahT_97EDfpa"
      },
      "source": [
        "visualize_model(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
